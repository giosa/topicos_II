#!/usr/bin/env python
"""
Script principal para pipeline WIDS 2024
Orquesta la carga, procesamiento, entrenamiento y predicci√≥n
"""

import sys
import argparse
from module_data import DataProcessor
from module_ml import ModelTrainer
import pandas as pd

def parse_arguments():
    """Parsear argumentos de l√≠nea de comandos"""
    parser = argparse.ArgumentParser(description='Pipeline WIDS 2024')
    parser.add_argument('--train_path', default='data/train.csv', 
                        help='Ruta al archivo train.csv')
    parser.add_argument('--test_path', default='data/test.csv', 
                        help='Ruta al archivo test.csv')
    parser.add_argument('--submission_path', default='data/sample_submission.csv',
                        help='Ruta al template de submission')
    parser.add_argument('--experiment_name', default='wids2024_experiment',
                        help='Nombre del experimento en MLflow')
    parser.add_argument('--cv_splits', type=int, default=5,
                        help='N√∫mero de folds para cross-validation')
    parser.add_argument('--compare_models', action='store_true',
                        help='Comparar m√∫ltiples modelos antes de entrenar el final')
    
    return parser.parse_args()

def main():
    """Funci√≥n principal del pipeline"""
    print("=" * 60)
    print("       PIPELINE WIDS 2024 - CLASIFICACI√ìN DE C√ÅNCER")
    print("=" * 60)
    
    # Parsear argumentos
    args = parse_arguments()
    
    try:
        # ===== 1. PROCESAMIENTO DE DATOS =====
        print("\n[1/4] üìä PROCESANDO DATOS...")
        processor = DataProcessor(
            train_path=args.train_path,
            test_path=args.test_path
        )
        
        X_train, y_train, X_test, feature_cols = processor.get_processed_data()
        
        print(f"   ‚Ä¢ Train shape: {X_train.shape}")
        print(f"   ‚Ä¢ Test shape: {X_test.shape}")
        print(f"   ‚Ä¢ Features: {feature_cols}")
        print(f"   ‚Ä¢ Clases: {y_train.unique()}")
        
        # ===== 2. COMPARACI√ìN DE MODELOS (OPCIONAL) =====
        trainer = ModelTrainer(experiment_name=args.experiment_name)
        
        if args.compare_models:
            print("\n[2/4] üî¨ COMPARANDO M√öLTIPLES MODELOS...")
            comparison_results = trainer.compare_multiple_models(X_train, y_train)
            print(f"‚úÖ Comparaci√≥n completada. Mejor modelo: {comparison_results.iloc[0]['Model']}")
            print(f"   ‚Ä¢ AUC: {comparison_results.iloc[0]['CV_AUC_Mean']:.4f}")
            print(f"   ‚Ä¢ Tiempo: {comparison_results.iloc[0]['Train_Time_Seconds']:.2f}s")
        
        # ===== 3. ENTRENAMIENTO DEL MODELO FINAL =====
        print("\n[3/4] ü§ñ ENTRENANDO MODELO FINAL (GridSearchCV)...")
        
        best_model, best_params, best_score = trainer.train_with_gridsearch(
            X_train=X_train,
            y_train=y_train,
            cv_splits=args.cv_splits
        )
        
        print(f"   ‚Ä¢ Mejor modelo: AdaBoost")
        print(f"   ‚Ä¢ Mejor AUC (CV): {best_score:.4f}")
        print(f"   ‚Ä¢ Mejores par√°metros: {best_params}")
        
        # ===== 4. PREDICCI√ìN =====
        print("\n[4/4] üîÆ GENERANDO PREDICCIONES...")
        predictions = trainer.predict_test_set(
            model=best_model,
            X_test=X_test,
            return_proba=True
        )
        
        # ===== 5. CREAR SUBMISSION =====
        print("\n[5/5] üíæ CREANDO ARCHIVO DE SUBMISSION...")
        submission_df = trainer.create_submission(
            predictions=predictions,
            test_df=processor.test_df,
            sample_submission_path=args.submission_path
        )
        
        # ===== RESUMEN FINAL =====
        print("\n" + "=" * 60)
        print("‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")
        print("=" * 60)
        if args.compare_models:
            print(f"üìä Comparaci√≥n de modelos: 7 modelos evaluados")
        print(f"üìÅ Archivos generados:")
        print(f"   ‚Ä¢ submission_final.csv (listo para Kaggle)")
        print(f"\nüìä Resumen del modelo final:")
        print(f"   ‚Ä¢ Features utilizadas: {len(feature_cols)}")
        print(f"   ‚Ä¢ Mejor AUC (CV): {best_score:.4f}")
        print(f"   ‚Ä¢ Predicciones: {len(predictions)} muestras")
        print(f"\nüîó MLflow:")
        print(f"   ‚Ä¢ Experimento: {args.experiment_name}")
        print(f"   ‚Ä¢ Modelo guardado en tracking")
        print("=" * 60)
        
        return 0
        
    except Exception as e:
        print(f"\n‚ùå ERROR en el pipeline: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())